{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPPNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# from concurrent.futures import thread # Parallelize comparisons\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "k_P_pairs = [\n",
        "    (16, 6),\n",
        "    (16, 3)\n",
        "]\n",
        "\n",
        "l   = 1 # No perturbation from l-diversity\n",
        "PAA = 6\n",
        "\n",
        "DATASETS = [\n",
        "    'facebook_microsoft.csv',\n",
        "    'facebook_palestine.csv',\n",
        "    'sales_transactions_dataset_weekly.csv'\n",
        "]\n",
        "\n",
        "ALGORITHMS = [\n",
        "    'naive',\n",
        "    'kapra'\n",
        "]\n",
        "\n",
        "DATA_DIR = 'data'\n",
        "SRC = 'k_P_anonymity.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "abs_data_dir = Path(os.path.dirname(os.path.abspath('__file__'))).parent / DATA_DIR\n",
        "abs_src_path = abs_data_dir.parent / SRC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(dataset):\n",
        "    abs_data_path = str(abs_data_dir / dataset)\n",
        "    errs = []\n",
        "\n",
        "    for algo in ALGORITHMS:\n",
        "        for k_P in k_P_pairs:\n",
        "            k, P = k_P\n",
        "\n",
        "            cmd = 'python {} {} {} {} {} {} {}'.format('\"' + str(abs_src_path) + '\"',\n",
        "                    algo, k, P, PAA, l, '\"' + abs_data_path + '\"')\n",
        "\n",
        "            try:\n",
        "                subprocess.run(cmd, shell=True, check=True)\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                errs.append(str(e))\n",
        "\n",
        "    if len(errs) == 0:\n",
        "        print('No errors found with dataset {}'.format(dataset))\n",
        "\n",
        "    return errs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_experiment_errs(res):\n",
        "    exper_errs = list(res)\n",
        "\n",
        "    for exper in exper_errs:\n",
        "        dataset, errs = exper\n",
        "\n",
        "        if len(errs) == 0:\n",
        "            continue\n",
        "\n",
        "        print('Found {} errors with dataset {}'.format(len(errs), dataset))\n",
        "\n",
        "        for err in errs:\n",
        "            print(err)\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    return exper_errs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with thread.ThreadPoolExecutor(max_workers=16) as exec:\n",
        "#     res = zip(DATASETS, list(exec.map(run_experiment, DATASETS))) # Store experiment results\n",
        "\n",
        "# # Print experiment errors\n",
        "# exper_errs = print_experiment_errs(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avoid GIL constraints #\n",
        "#########################\n",
        "\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    with ProcessPoolExecutor(max_workers=16) as pool:\n",
        "        res = zip(DATASETS, list(pool.map(run_experiment, DATASETS))) # Store experiment results\n",
        "\n",
        "    # Print experiment errors\n",
        "    exper_errs = print_experiment_errs(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}